---
title: "Skewness & Kurtosis"
author: "Said Sharify"
date: "2022-08-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Skewness

Disparity is when the data in a dataset is unbalanced. Skewness allows us to calculate the symmetry of our dataset. A dataset is symmetric when the data are equally distributed on either side of the mean, the Skewness equal to 0, means the dataset is symmetric.

Mathematically it is given by :
Pearson’s median skewness = 3 (Mean - Median) / Standard Deviation

If the Skewness is greater than 0, then the dataset is skewed to the right. That is to say that the majority of the data is on the left and the outliers are on the right. Indeed we can see on the graph that the dataset is not symmetric and is skewed on the right and the majority of vehicles have a range between 200 km and 400 km :

```{r Histogram}
library(moments)

ElectricCar <- read.csv("~/ElectricCar.csv")
hist(ElectricCar$Range_Km)

```

Right skew: mean > median

```{r Skewness}
library(moments)
skewness(ElectricCar$Range_Km)
```


## Kurtosis

The Kurtosis allows us to calculate the flattening of our curve. A dataset is flat when the data is evenly distributed. We have positive Kurtosis and negative Kurtosis. Kurtos is a measure of the peakedness of the distribution or relative to normal. For symmetric distributions negative Kurtosis implies wider peak and thinner talls.

```{r Kurtosis}
library(moments)
kurtosis(ElectricCar$Range_Km)
```

### SRS (Simple random sampling)

With Population Parameters :
μ for Mean, σ^2 for Variance, σ for Standard Deviation, π for Proportion, 


and with Sample Statistics :
x̄ for Mean, S^2 for Variance, S for Standard Deviation, P for Proportion.


### Sample Size

#### Generic rules
  - Each data point in the sample is independent of the other.
  - The sample size is large enough
  - The distribution of data could be symmetry with/without outliers
  - If data is quite symmetric and has few outliers, even small samples are fine. Otherwise, we need larger samples.
  - A sample size of 30 is considered large enough, but that may / may not be adequate.


#### More precise conditions
 - n > 10[k3]^2, where K3 is sample Skewness,
 - n > 10[K2], where K2 is sample Kurtosis.


